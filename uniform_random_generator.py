# Lark.generate() implements McKenzie, B. (1997). Generating Strings at Random from a Context Free Grammar. https://doi.org/10/97

import sys
from typing import List, Dict, Union, Optional

from lark import Lark, Tree
import lark.grammar


sys.setrecursionlimit(2000)

# Preprocessing 

symbol = Union[lark.grammar.NonTerminal, lark.grammar.Terminal]

def build_rule_map(parser: Lark) -> None:
    nt_map: Dict[lark.grammar.NonTerminal, int] = {}
    production_list: List[List[symbol]] = []
    nt_cnt = 0
    for rule in parser.rules:
        origin = rule.origin
        if origin not in nt_map:
            nt_map[origin] = nt_idx = nt_cnt
            production_list.append([])
            nt_cnt += 1
        else:
            nt_idx = nt_map[origin]
        production_list[nt_idx].append(rule.expansion)
    parser.nt_map = nt_map
    parser.production_list = production_list

def nt_idx(parser: Lark, nt: lark.grammar.NonTerminal) -> int:
    "Return non-terminal index i in production rules of grammar"
    assert nt in parser.nt_map
    return parser.nt_map[nt]

f_memo: List[List[Optional[List[int]]]]
f_prime_memo: List[List[List[List[Optional[List[int]]]]]]

def build_f_memo(parser: Lark, n: int):
    global f_memo
    f_memo_tmp = [[] for _ in range(n + 1)]
    for _n in range(n + 1):
        f_memo_tmp[_n] = [[] for _ in range(len(parser.nt_map.keys()))]
    for _n in range(n + 1):
        for i in range(len(parser.nt_map.keys())):
            f_memo_tmp[_n][i] = None
    f_memo = f_memo_tmp

def build_f_prime_memo(parser: Lark, n: int):
    global f_prime_memo
    f_prime_memo_tmp = [[] for _ in range(n + 1)]
    for _n in range(n + 1):
        f_prime_memo_tmp[_n] = [[] for _ in range(len(parser.nt_map.keys()))]
    for _n in range(n + 1):
        for i in range(len(parser.nt_map.keys())):
            f_prime_memo_tmp[_n][i] = [[] for _ in range(len(parser.production_list[i]))]
    for _n in range(n + 1):
        for i in range(len(parser.nt_map.keys())):
            for j in range(len(parser.production_list[i])):
                f_prime_memo_tmp[_n][i][j] = [None for _ in range(len(parser.production_list[i][j]))]
    f_prime_memo = f_prime_memo_tmp

def f(parser: Lark, n: int, i: int) -> List[int]:
    "Return a list giving the number of strings of length n generated for each production N_i -> \alpha_(i,j)"
    global f_memo
    if f_memo[n][i] is None:
        f_memo[n][i] = [sum(f_prime(parser, n, i, j, 0)) for j in range(len(parser.production_list[i]))]
    # print('f', n, i, f_memo[n][i])
    return f_memo[n][i]

# n -> string length [0, n]
# i -> non-terminal index [0, ||N||)
# j -> production rule index for a given non-terminal i, s_i total production rules per non-terminal i
# k -> RHS symbol index for a given production rule (i, j)
def f_prime(parser: Lark, n: int, i: int, j: int, k: int) -> List[int]:
    """
    Return the number of strings of length n generated by the final symbols
    x_(i,j,k) ... x_(i,j,t_(i,j)) for the RHS of the production \pi_(i,j): N_i -> x_(i,j,1) ... x_(i,j,t_(i,j))
    for each of the possible ways in which the n terminals can be split between the first symbol x_(i,j,k)
    and the remaining symbols
    """
    global f_prime_memo
    if n < 0:
        return []
    if f_prime_memo[n][i][j][k] is None:
        if n == 0:
            f_prime_memo[n][i][j][k] = []
        elif type(parser.production_list[i][j][k]) == lark.grammar.Terminal:
            if k + 1 == len(parser.production_list[i][j]): # if last symbol of expansion
                if n == 1:
                    f_prime_memo[n][i][j][k] = [1]
                else:
                    f_prime_memo[n][i][j][k] = [0]
            else:
                f_prime_memo[n][i][j][k] = [sum(f_prime(parser, n - 1, i, j, k + 1))]
        elif k + 1 == len(parser.production_list[i][j]):
            idx = nt_idx(parser, parser.production_list[i][j][k])
            f_prime_memo[n][i][j][k] = [sum(f(parser, n, idx))]
        else:
            idx = nt_idx(parser, parser.production_list[i][j][k])
            f_prime_memo[n][i][j][k] = [sum(f(parser, l, idx)) * sum(f_prime(parser, n - l, i, j, k + 1)) for l in range(1, n - len(parser.production_list[i][j]) + (k + 1) + 1)]
    # print('f_prime', n, i, j, k, f_prime_memo[n][i][j][k])
    return f_prime_memo[n][i][j][k]

# String Generation

import random

def choose(l: List[int]) -> int:
    "Return an index i between [0, len(l)) at random with probability l[i] / sum(l)"
    return random.choices(range(len(l)), weights=l, k=1)[0]

def g(parser: Lark, n: int, i: int) -> List[lark.grammar.Terminal]:
    "Generate a string of length n uniformly at random from a non-terminal N_i"
    if n < 0:
        return []
    r = choose(f(parser, n, i))
    return g_prime(parser, n, i, r, 0)

def g_prime(parser: Lark, n: int, i: int, j: int, k: int) -> List[lark.grammar.Terminal]:
    """
    Generate a string of length n uniformly at random from among all the string derivable from the symbols
    x_(i,j,k) ... x_(i,j,t_(i,j)) taken from the RHS of the production N_i -> \alpha_(i,j)
    """
    if n < 0:
        return []
    if type(parser.production_list[i][j][k]) == lark.grammar.Terminal:
        if k + 1 == len(parser.production_list[i][j]):
            return [parser.production_list[i][j][k]]
        else:
            return [parser.production_list[i][j][k]] + g_prime(parser, n - 1, i, j, k + 1)
    if k + 1 == len(parser.production_list[i][j]):
        return g(parser, n, nt_idx(parser, parser.production_list[i][j][k]))
    else:
        weights = f_prime(parser, n, i, j, k)
        # print('g_prime', weights)
        # assert len(weights) == len(parser.production_list[i]), f"{len(weights)} vs. {len(parser.production_list[i])}"
        l = choose(weights) + 1
        return g(parser, l, nt_idx(parser, parser.production_list[i][j][k])) + g_prime(parser, n - l, i, j, k + 1)


# follows API of fuzzuf -> Nautilus -> generator tool
# https://github.com/fuzzuf/fuzzuf/blob/ac23ff23ed82f051e6f7fd551bddf6640de1080b/docs/algorithms/nautilus/algorithm_en.md
def generate(parser: Lark, tree_depth: int = 10, number_of_trees: int = 1) -> List[Tree]:
    build_rule_map(parser)
    # print(parser.nt_map, parser.production_list)
    build_f_memo(parser, tree_depth)
    build_f_prime_memo(parser, tree_depth)
    # print('f', f_memo)
    # print("f'", f_prime_memo)
    results = [g(parser, tree_depth, 0) for _ in range(number_of_trees)]
    return results

import code

if __name__ == '__main__':
    with open('microrts-dsl.lark') as dsl_file:
        parser = Lark(dsl_file, parser='lalr', keep_all_tokens=True, start='program')
    # s = parser.rules[0].origin
    # s_prime = parser.rules[1].expansion[1]
    # print(s == s_prime)
    # print(dir(parser))
    # print(parser.terminals)
    print(dir(parser))
    # code.interact(local=locals())
    results = generate(parser, tree_depth=200, number_of_trees=5)
    results_str = [' '.join([parser._terminals_dict[terminal.name].pattern.value for terminal in result]) for result in results]
    print('\n'.join(results_str))
    # print(dir(results[0][0]))
    # print(results[0][0].__slots__)